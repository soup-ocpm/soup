# SOuP
Project created for the Group Project exam of the third year of computer science in Camerino.

## Description
This project is based on the creation of a WebApp that allows the end user to create a graph <br>
starting from his data (event - log) saved in a .csv file with the aim of carrying out object-centric process-mining. <br>
All this occurs through the use of a Neo4j database which allows the saving of the generated data of interest.
Currently the system, in addition to carrying out the main purpose of creating graphs based on the data of interest, <br>
also allows the download of them in SVG format, the elimination of the data obtained in the corresponding Database of interest, <br>
as well as the possibility of performing groupings to optimize the overall usability of the results and the study of the data of interest.

### PM vs. Object-Centric PM
- Process Mining
Process mining is a discipline that is based on the use of data (generated by information systems) to extract useful information
offering a detailed and objective vision of company processes. This with the aim of visualizing, monitoring and above all optimizing the main activities.
Traditional process mining follows a plausible linear approach and can focus primarily on the flow of core process activities. <br>
However, this often leads to a limited vision, in which specific details or attributes may be overlooked and therefore not taken into consideration.
- Object-centric process mining emerged to address the limitation of traditional process mining just described.
This methodology focuses not only on the main activities of the process, but also on all entities involved and the attributes associated with them during the event.
Through object-centric it is possible to view the graph in detail and with all the attributes.

## Tecnhnologies
As previously described, to create the final project that satisfied all the requirements, 
various technologies were necessary which in turn were studied and explored in depth during the first weeks of development.

### 1. Memgraph Database
One of the fundamental technologies on which the main purpose of the project was based is certainly the Graph database. <br>
As a Graph database, the famous and professional Memgraph environment was used as requested.
Useful links : 
- [Memgraph](https://memgraph.com/)
- [Chyper Query Language](https://neo4j.com/product/cypher-graph-query-language/?utm_source=google&utm_medium=PaidSearch&utm_campaign=GDB&utm_content=EMEA-X-Awareness-GDB-Text&utm_term=cypher%20query%20language&gad_source=1&gclid=CjwKCAiA9ourBhAVEiwA3L5RFhfAegfrPme8ND2NcBymbz8fhWHLrDI-HbSaK5lhBIA0kp-iR8ZZgRoC47wQAvD_BwE)

### 2. Python
As regards the creation of the Backend server, the Python programming language was used as requested but above all Flask
which allows you to create Server applications for APIs. The Backend in this project is fundamental as it interacts through the 
use of libraries provided by Neo4j, with the Neo4j database in question, for the creation of graphs based on the end user's data. 
Obviously and temporarily the saving was made in a local Neo4j database.
Useful links : 
- [Python](https://www.python.org/)
- [Flask](https://flask.palletsprojects.com/en/3.0.x/)
- [Neo4j Python library](https://neo4j.com/developer/python/)

### 3. Angular
The professional Angular framework was used as a frontend, therefore a fundamental part of the View, which allowed 
the application to be developed in a scalable and usable way. 
Within Angular, libraries have been used to create graphs based on nodes and relations.
Useful links: 
- [Angular](https://angular.io/)
- [Dagre-d3](https://www.npmjs.com/package/dagre-d3)
and other library visible in package.json.

## Use case
As described previously, the tool allows the end user to upload a .csv file containing evet logs and create EKG-based graphs. <br>
First, go to the corresponding "Upload CSV" section and follow the tool's instructions to correctly upload the csv file. <br>
Once loaded, the file will be parsed and the user can see a preview of the entities and properties of the file through the table. <br>
A Sidebar coming from the right has the task of letting the user filter the entities and properties to take into consideration for his analysis.<br>

[Filter data](https://bitbucket.org/proslabteam/easy-knowledge-graph/raw/c4753811b425eb364664e811c11c984a1b51c275/ekg_screenshots/screen1.png)

Once this first phase is completed, the graph will be automatically generated within our Memgraph database and the graph data will be reported in the form of Cards, as illustrated:

[Cards data](https://bitbucket.org/proslabteam/easy-knowledge-graph/raw/c4753811b425eb364664e811c11c984a1b51c275/ekg_screenshots/screen2.png)

Then you can expand the cards to see the corresponding and specific JSON of the newly created data, with the possibility of searching within the JSON or even downloading it : 

[Card visualization](https://bitbucket.org/proslabteam/easy-knowledge-graph/raw/c4753811b425eb364664e811c11c984a1b51c275/ekg_screenshots/screen3.png)

In the Sidebar coming from the right, you can perform operations such as downloading the complete JSON of the Graph, deleting the graph or above all grouping the nodes <br> 
to create the graph composed of aggregate nodes (Class Graph). Again, in this section the previously selected entities are presented, with warnings in case some nodes have that null property.

[Class graph](https://bitbucket.org/proslabteam/easy-knowledge-graph/raw/c4753811b425eb364664e811c11c984a1b51c275/ekg_screenshots/screen4.png)

Once the attributes to aggregate the nodes have been chosen, the Classes node will be created, and the user will automatically be redirected to the page which aims to view the complete graph. 

In this section you can already place studies and analyses, navigating within the graprh. Above all, you can search fo nodes or relationships, and through the Sidebar you can carry out other <br> 
operations such as customizing the graph view, exporting the graph to .svg or deleting the graph.

[Search nodes](https://bitbucket.org/proslabteam/easy-knowledge-graph/raw/c4753811b425eb364664e811c11c984a1b51c275/ekg_screenshots/screen5.png)

[Change graph visualization](https://bitbucket.org/proslabteam/easy-knowledge-graph/raw/c4753811b425eb364664e811c11c984a1b51c275/ekg_screenshots/screen6.png)

At the top left there is an arrow to return to the previous screen. In this case the tool recognizes that an aggregate graph has already been created (or in any case is present within the Database)<br> 
so you have the possibility to see the graph or create a new one (the current graph will be eliminated).

[New class graph](https://bitbucket.org/proslabteam/easy-knowledge-graph/raw/c4753811b425eb364664e811c11c984a1b51c275/ekg_screenshots/screen7.png)

## Tool Setup - Instruction

The first step is to clone the project. <br> ([Clone a Git repository](https://support.atlassian.com/bitbucket-cloud/docs/clone-a-git-repository/))<br>
You must have Git downloaded into your computer. If Git is not present, you will receive an error message.<br>
To download Git, go to the specific page:

[Download Git](https://git-scm.com/downloads)

### Start tool by Docker
First, install Docker inside your computer.

[Download Docker](https://www.docker.com/get-started/)

Once Docker has been correctly downloaded, open the terminal inside the main folder of the (cloned) project.  
At this point, you can run the following commands from the terminal to create a Container in Docker made up of all the projects:<br>

```
docker-compose -p soup-tool up --build
```

When the command is finished, a Container is automatically created by Docker compose composed of the following sub-containers (all already started): 

- Angular container: represents the web tool, contactable at the <h4>lcalhost:4200</h4>
- Python container (Backend): represents the Backend and Engine of the system, contactable at the <h4>lcalhost:8080</h4>
- Memgraph container: in this container, the Memgraph database runs which offers 3 different ports.The most important is certainly<h4>lcalhost:3000</h4>which, if navigated, will open Memgraph Lab.



## Final Product
The user has the possibility to upload his own .csv file containing the data of interest via Drag&Drop. 
Once the .csv file is loaded, the user has the possibility to filter the data and therefore the columns of his .csv file.
Once this operation has been done (optional) the Server will begin to create the Graph of interest through queries to the Neo4j Database
and will return the generated graph as a result. Obviously, the user has the possibility to download his graph in .svg format, as
the possibility of eliminating it, but above all grouping the entities by Classes, in such a way as to obtain a new graph of interest.
All this achieved thanks to the Neo4j, Python and Angular libraries and documentation.